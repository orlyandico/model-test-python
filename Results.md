Batch Analysis Report
=====================
Batch Directories: results
Analysis Date: 2026-02-08 17:22:35

Model Performance Summary:
--------------------------
global.anthropic.claude-sonnet-4-5-20250929-v1_0:
  Batch Source: results
  Runs: 5, Unique Tests: 17
  Average Latency per LLM Call: 2.89s
  Tool Invocation (Binary, macro-averaged):
    Precision: 1.000 (60/60)
    Recall: 1.000 (60/60)
    F1: 1.000
  Tool Selection (macro-averaged):
    Precision: 1.000 (135/135)
    Recall: 0.931 (135/145)
    F1: 0.964
  Per-run F1 scores:
    Run 1: Invocation=1.000, Selection=0.964 (agent_test_results_global.anthropic.claude-sonnet-4-5-20250929-v1_0_20260118_164705.json)
    Run 2: Invocation=1.000, Selection=0.964 (agent_test_results_global.anthropic.claude-sonnet-4-5-20250929-v1_0_20260118_191215.json)
    Run 3: Invocation=1.000, Selection=0.964 (agent_test_results_global.anthropic.claude-sonnet-4-5-20250929-v1_0_20260122_181026.json)
    Run 4: Invocation=1.000, Selection=0.964 (agent_test_results_global.anthropic.claude-sonnet-4-5-20250929-v1_0_20260118_215305.json)
    Run 5: Invocation=1.000, Selection=0.964 (agent_test_results_global.anthropic.claude-sonnet-4-5-20250929-v1_0_20260118_162458.json)

global.anthropic.claude-sonnet-4-20250514-v1_0:
  Batch Source: results
  Runs: 5, Unique Tests: 17
  Average Latency per LLM Call: 2.48s
  Tool Invocation (Binary, macro-averaged):
    Precision: 1.000 (60/60)
    Recall: 1.000 (60/60)
    F1: 1.000
  Tool Selection (macro-averaged):
    Precision: 1.000 (133/133)
    Recall: 0.917 (133/145)
    F1: 0.957
  Per-run F1 scores:
    Run 1: Invocation=1.000, Selection=0.964 (agent_test_results_global.anthropic.claude-sonnet-4-20250514-v1_0_20260118_162642.json)
    Run 2: Invocation=1.000, Selection=0.945 (agent_test_results_global.anthropic.claude-sonnet-4-20250514-v1_0_20260118_191359.json)
    Run 3: Invocation=1.000, Selection=0.964 (agent_test_results_global.anthropic.claude-sonnet-4-20250514-v1_0_20260122_181242.json)
    Run 4: Invocation=1.000, Selection=0.964 (agent_test_results_global.anthropic.claude-sonnet-4-20250514-v1_0_20260118_215451.json)
    Run 5: Invocation=1.000, Selection=0.945 (agent_test_results_global.anthropic.claude-sonnet-4-20250514-v1_0_20260118_164853.json)

global.anthropic.claude-haiku-4-5-20251001-v1_0:
  Batch Source: results
  Runs: 5, Unique Tests: 17
  Average Latency per LLM Call: 1.67s
  Tool Invocation (Binary, macro-averaged):
    Precision: 1.000 (60/60)
    Recall: 1.000 (60/60)
    F1: 1.000
  Tool Selection (macro-averaged):
    Precision: 0.940 (140/149)
    Recall: 0.959 (140/146)
    F1: 0.949
  Per-run F1 scores:
    Run 1: Invocation=1.000, Selection=0.949 (agent_test_results_global.anthropic.claude-haiku-4-5-20251001-v1_0_20260118_164602.json)
    Run 2: Invocation=1.000, Selection=0.949 (agent_test_results_global.anthropic.claude-haiku-4-5-20251001-v1_0_20260118_215157.json)
    Run 3: Invocation=1.000, Selection=0.949 (agent_test_results_global.anthropic.claude-haiku-4-5-20251001-v1_0_20260118_162353.json)
    Run 4: Invocation=1.000, Selection=0.949 (agent_test_results_global.anthropic.claude-haiku-4-5-20251001-v1_0_20260118_191102.json)
    Run 5: Invocation=1.000, Selection=0.949 (agent_test_results_global.anthropic.claude-haiku-4-5-20251001-v1_0_20260122_180834.json)

zai-org_glm-4.7-maas:
  Batch Source: results
  Runs: 6, Unique Tests: 17
  Average Latency per LLM Call: 1.39s
  Tool Invocation (Binary, macro-averaged):
    Precision: 1.000 (72/72)
    Recall: 1.000 (72/72)
    F1: 1.000
  Tool Selection (macro-averaged):
    Precision: 0.930 (160/172)
    Recall: 0.920 (160/174)
    F1: 0.925
  Per-run F1 scores:
    Run 1: Invocation=1.000, Selection=0.931 (agent_test_results_zai-org_glm-4.7-maas_20260208_140624.json)
    Run 2: Invocation=1.000, Selection=0.931 (agent_test_results_zai-org_glm-4.7-maas_20260208_141038.json)
    Run 3: Invocation=1.000, Selection=0.931 (agent_test_results_zai-org_glm-4.7-maas_20260208_140155.json)
    Run 4: Invocation=1.000, Selection=0.912 (agent_test_results_zai-org_glm-4.7-maas_20260208_135946.json)
    Run 5: Invocation=1.000, Selection=0.912 (agent_test_results_zai-org_glm-4.7-maas_20260208_135827.json)
    Run 6: Invocation=1.000, Selection=0.931 (agent_test_results_zai-org_glm-4.7-maas_20260208_140457.json)

global.amazon.nova-2-lite-v1_0:
  Batch Source: results
  Runs: 12, Unique Tests: 17
  Average Latency per LLM Call: 0.84s
  Tool Invocation (Binary, macro-averaged):
    Precision: 1.000 (144/144)
    Recall: 1.000 (144/144)
    F1: 1.000
  Tool Selection (macro-averaged):
    Precision: 0.946 (312/330)
    Recall: 0.897 (312/348)
    F1: 0.920
  Per-run F1 scores:
    Run 1: Invocation=1.000, Selection=0.929 (agent_test_results_global.amazon.nova-2-lite-v1_0_20260208_171824.json)
    Run 2: Invocation=1.000, Selection=0.929 (agent_test_results_global.amazon.nova-2-lite-v1_0_20260208_171603.json)
    Run 3: Invocation=1.000, Selection=0.929 (agent_test_results_global.amazon.nova-2-lite-v1_0_20260122_180751.json)
    Run 4: Invocation=1.000, Selection=0.912 (agent_test_results_global.amazon.nova-2-lite-v1_0_20260208_171741.json)
    Run 5: Invocation=1.000, Selection=0.929 (agent_test_results_global.amazon.nova-2-lite-v1_0_20260208_171652.json)
    Run 6: Invocation=1.000, Selection=0.912 (agent_test_results_global.amazon.nova-2-lite-v1_0_20260208_171953.json)
    Run 7: Invocation=1.000, Selection=0.929 (agent_test_results_global.amazon.nova-2-lite-v1_0_20260118_191022.json)
    Run 8: Invocation=1.000, Selection=0.912 (agent_test_results_global.amazon.nova-2-lite-v1_0_20260208_172038.json)
    Run 9: Invocation=1.000, Selection=0.912 (agent_test_results_global.amazon.nova-2-lite-v1_0_20260118_215112.json)
    Run 10: Invocation=1.000, Selection=0.912 (agent_test_results_global.amazon.nova-2-lite-v1_0_20260118_164521.json)
    Run 11: Invocation=1.000, Selection=0.912 (agent_test_results_global.amazon.nova-2-lite-v1_0_20260118_162312.json)
    Run 12: Invocation=1.000, Selection=0.929 (agent_test_results_global.amazon.nova-2-lite-v1_0_20260208_171909.json)

qwen3_8b:
  Batch Source: results
  Runs: 8, Unique Tests: 17
  Average Latency per LLM Call: 9.22s
  Tool Invocation (Binary, macro-averaged):
    Precision: 1.000 (96/96)
    Recall: 1.000 (96/96)
    F1: 1.000
  Tool Selection (macro-averaged):
    Precision: 0.947 (203/215)
    Recall: 0.875 (203/232)
    F1: 0.909
  Per-run F1 scores:
    Run 1: Invocation=1.000, Selection=0.945 (agent_test_results_qwen3_8b_20260118_151304.json)
    Run 2: Invocation=1.000, Selection=0.929 (agent_test_results_qwen3_8b_20260123_080417.json)
    Run 3: Invocation=1.000, Selection=0.857 (agent_test_results_qwen3_8b_20260118_155412.json)
    Run 4: Invocation=1.000, Selection=0.929 (agent_test_results_qwen3_8b_20260122_214922.json)
    Run 5: Invocation=1.000, Selection=0.929 (agent_test_results_qwen3_8b_20260118_173859.json)
    Run 6: Invocation=1.000, Selection=0.926 (agent_test_results_qwen3_8b_20260123_191021.json)
    Run 7: Invocation=1.000, Selection=0.847 (agent_test_results_qwen3_8b_20260118_184404.json)
    Run 8: Invocation=1.000, Selection=0.909 (agent_test_results_qwen3_8b_20260122_222826.json)

qwen3_1.7b:
  Batch Source: results
  Runs: 21, Unique Tests: 17
  Average Latency per LLM Call: 2.77s
  Tool Invocation (Binary, macro-averaged):
    Precision: 1.000 (252/252)
    Recall: 1.000 (252/252)
    F1: 1.000
  Tool Selection (macro-averaged):
    Precision: 0.908 (552/610)
    Recall: 0.906 (552/609)
    F1: 0.906
  Per-run F1 scores:
    Run 1: Invocation=1.000, Selection=0.909 (agent_test_results_qwen3_1.7b_20260208_142518.json)
    Run 2: Invocation=1.000, Selection=0.842 (agent_test_results_qwen3_1.7b_20260118_145616.json)
    Run 3: Invocation=1.000, Selection=0.871 (agent_test_results_qwen3_1.7b_20260208_144333.json)
    Run 4: Invocation=1.000, Selection=0.931 (agent_test_results_qwen3_1.7b_20260208_143631.json)
    Run 5: Invocation=1.000, Selection=0.871 (agent_test_results_qwen3_1.7b_20260118_154345.json)
    Run 6: Invocation=1.000, Selection=0.900 (agent_test_results_qwen3_1.7b_20260208_143807.json)
    Run 7: Invocation=1.000, Selection=0.929 (agent_test_results_qwen3_1.7b_20260208_144538.json)
    Run 8: Invocation=1.000, Selection=0.931 (agent_test_results_qwen3_1.7b_20260122_221600.json)
    Run 9: Invocation=1.000, Selection=0.947 (agent_test_results_qwen3_1.7b_20260118_150246.json)
    Run 10: Invocation=1.000, Selection=0.947 (agent_test_results_qwen3_1.7b_20260118_172820.json)
    Run 11: Invocation=1.000, Selection=0.912 (agent_test_results_qwen3_1.7b_20260208_144725.json)
    Run 12: Invocation=1.000, Selection=0.912 (agent_test_results_qwen3_1.7b_20260123_075209.json)
    Run 13: Invocation=1.000, Selection=0.909 (agent_test_results_qwen3_1.7b_20260122_213944.json)
    Run 14: Invocation=1.000, Selection=0.947 (agent_test_results_qwen3_1.7b_20260208_143255.json)
    Run 15: Invocation=1.000, Selection=0.931 (agent_test_results_qwen3_1.7b_20260208_143124.json)
    Run 16: Invocation=1.000, Selection=0.867 (agent_test_results_qwen3_1.7b_20260208_144004.json)
    Run 17: Invocation=1.000, Selection=0.881 (agent_test_results_qwen3_1.7b_20260208_142203.json)
    Run 18: Invocation=1.000, Selection=0.912 (agent_test_results_qwen3_1.7b_20260208_144155.json)
    Run 19: Invocation=1.000, Selection=0.867 (agent_test_results_qwen3_1.7b_20260123_185837.json)
    Run 20: Invocation=1.000, Selection=0.900 (agent_test_results_qwen3_1.7b_20260208_143436.json)
    Run 21: Invocation=1.000, Selection=0.912 (agent_test_results_qwen3_1.7b_20260118_183209.json)

Qwen3-Coder-Next-UD-Q3_K_XL.gguf:
  Batch Source: results
  Runs: 6, Unique Tests: 17
  Average Latency per LLM Call: 1.77s
  Tool Invocation (Binary, macro-averaged):
    Precision: 1.000 (72/72)
    Recall: 1.000 (72/72)
    F1: 1.000
  Tool Selection (macro-averaged):
    Precision: 0.915 (151/165)
    Recall: 0.887 (151/170)
    F1: 0.901
  Per-run F1 scores:
    Run 1: Invocation=1.000, Selection=0.929 (agent_test_results_Qwen3-Coder-Next-UD-Q3_K_XL.gguf_20260207_143959.json)
    Run 2: Invocation=1.000, Selection=0.881 (agent_test_results_Qwen3-Coder-Next-UD-Q3_K_XL.gguf_20260207_144846.json)
    Run 3: Invocation=1.000, Selection=0.912 (agent_test_results_Qwen3-Coder-Next-UD-Q3_K_XL.gguf_20260207_145242.json)
    Run 4: Invocation=1.000, Selection=0.912 (agent_test_results_Qwen3-Coder-Next-UD-Q3_K_XL.gguf_20260207_144131.json)
    Run 5: Invocation=1.000, Selection=0.857 (agent_test_results_Qwen3-Coder-Next-UD-Q3_K_XL.gguf_20260207_144339.json)
    Run 6: Invocation=1.000, Selection=0.912 (agent_test_results_Qwen3-Coder-Next-UD-Q3_K_XL.gguf_20260207_143731.json)

glm-4.7-flash:
  Batch Source: results
  Runs: 13, Unique Tests: 17
  Average Latency per LLM Call: 3.46s
  Tool Invocation (Binary, macro-averaged):
    Precision: 1.000 (155/155)
    Recall: 0.994 (155/156)
    F1: 0.997
  Tool Selection (macro-averaged):
    Precision: 0.925 (339/367)
    Recall: 0.878 (339/386)
    F1: 0.900
  Per-run F1 scores:
    Run 1: Invocation=1.000, Selection=0.889 (agent_test_results_glm-4.7-flash_20260122_000053.json)
    Run 2: Invocation=0.957, Selection=0.893 (agent_test_results_glm-4.7-flash_20260122_001700.json)
    Run 3: Invocation=1.000, Selection=0.915 (agent_test_results_glm-4.7-flash_20260122_000316.json)
    Run 4: Invocation=1.000, Selection=0.915 (agent_test_results_glm-4.7-flash_20260123_142340.json)
    Run 5: Invocation=1.000, Selection=0.889 (agent_test_results_glm-4.7-flash_20260121_235744.json)
    Run 6: Invocation=1.000, Selection=0.842 (agent_test_results_glm-4.7-flash_20260122_000618.json)
    Run 7: Invocation=1.000, Selection=0.968 (agent_test_results_glm-4.7-flash_20260122_000901.json)
    Run 8: Invocation=1.000, Selection=0.881 (agent_test_results_glm-4.7-flash_20260122_001129.json)
    Run 9: Invocation=1.000, Selection=0.862 (agent_test_results_glm-4.7-flash_20260121_235513.json)
    Run 10: Invocation=1.000, Selection=0.873 (agent_test_results_glm-4.7-flash_20260121_231229.json)
    Run 11: Invocation=1.000, Selection=0.947 (agent_test_results_glm-4.7-flash_20260121_235230.json)
    Run 12: Invocation=1.000, Selection=0.929 (agent_test_results_glm-4.7-flash_20260121_231517.json)
    Run 13: Invocation=1.000, Selection=0.897 (agent_test_results_glm-4.7-flash_20260122_001421.json)

gemini-2.0-flash:
  Batch Source: results
  Runs: 6, Unique Tests: 17
  Average Latency per LLM Call: 1.29s
  Tool Invocation (Binary, macro-averaged):
    Precision: 1.000 (72/72)
    Recall: 1.000 (72/72)
    F1: 1.000
  Tool Selection (macro-averaged):
    Precision: 1.000 (135/135)
    Recall: 0.776 (135/174)
    F1: 0.873
  Per-run F1 scores:
    Run 1: Invocation=1.000, Selection=0.863 (agent_test_results_gemini-2.0-flash_20260208_134449.json)
    Run 2: Invocation=1.000, Selection=0.863 (agent_test_results_gemini-2.0-flash_20260208_134028.json)
    Run 3: Invocation=1.000, Selection=0.863 (agent_test_results_gemini-2.0-flash_20260208_130439.json)
    Run 4: Invocation=1.000, Selection=0.863 (agent_test_results_gemini-2.0-flash_20260208_130622.json)
    Run 5: Invocation=1.000, Selection=0.926 (agent_test_results_gemini-2.0-flash_20260208_130306.json)
    Run 6: Invocation=1.000, Selection=0.863 (agent_test_results_gemini-2.0-flash_20260208_130825.json)

gemini-2.5-pro:
  Batch Source: results
  Runs: 13, Unique Tests: 17
  Average Latency per LLM Call: 4.51s
  Tool Invocation (Binary, macro-averaged):
    Precision: 1.000 (153/153)
    Recall: 0.981 (153/156)
    F1: 0.990
  Tool Selection (macro-averaged):
    Precision: 0.986 (274/278)
    Recall: 0.778 (274/351)
    F1: 0.867
  Per-run F1 scores:
    Run 1: Invocation=1.000, Selection=0.964 (agent_test_results_gemini-2.5-pro_20260208_150303.json)
    Run 2: Invocation=1.000, Selection=0.791 (agent_test_results_gemini-2.5-pro_20260208_151112.json)
    Run 3: Invocation=1.000, Selection=0.852 (agent_test_results_gemini-2.5-pro_20260208_152615.json)
    Run 4: Invocation=0.957, Selection=0.870 (agent_test_results_gemini-2.5-pro_20260208_151711.json)
    Run 5: Invocation=0.957, Selection=0.816 (agent_test_results_gemini-2.5-pro_20260208_150524.json)
    Run 6: Invocation=1.000, Selection=0.926 (agent_test_results_gemini-2.5-pro_20260208_131700.json)
    Run 7: Invocation=1.000, Selection=0.889 (agent_test_results_gemini-2.5-pro_20260208_131347.json)
    Run 8: Invocation=1.000, Selection=0.889 (agent_test_results_gemini-2.5-pro_20260208_151406.json)
    Run 9: Invocation=1.000, Selection=0.870 (agent_test_results_gemini-2.5-pro_20260208_152829.json)
    Run 10: Invocation=0.957, Selection=0.885 (agent_test_results_gemini-2.5-pro_20260208_134607.json)
    Run 11: Invocation=1.000, Selection=0.810 (agent_test_results_gemini-2.5-pro_20260208_150001.json)
    Run 12: Invocation=1.000, Selection=0.926 (agent_test_results_gemini-2.5-pro_20260208_152326.json)
    Run 13: Invocation=1.000, Selection=0.791 (agent_test_results_gemini-2.5-pro_20260208_152055.json)

qwen3_4b:
  Batch Source: results
  Runs: 22, Unique Tests: 17
  Average Latency per LLM Call: 17.81s
  Tool Invocation (Binary, macro-averaged):
    Precision: 1.000 (250/250)
    Recall: 0.947 (250/264)
    F1: 0.972
  Tool Selection (macro-averaged):
    Precision: 0.958 (493/516)
    Recall: 0.785 (493/626)
    F1: 0.859
  Per-run F1 scores:
    Run 1: Invocation=0.957, Selection=0.792 (agent_test_results_qwen3_4b_20260122_072709.json)
    Run 2: Invocation=0.957, Selection=0.885 (agent_test_results_qwen3_4b_20260122_070602.json)
    Run 3: Invocation=1.000, Selection=0.909 (agent_test_results_qwen3_4b_20260118_154539.json)
    Run 4: Invocation=0.957, Selection=0.808 (agent_test_results_qwen3_4b_20260122_093114.json)
    Run 5: Invocation=1.000, Selection=0.800 (agent_test_results_qwen3_4b_20260122_071553.json)
    Run 6: Invocation=0.957, Selection=0.792 (agent_test_results_qwen3_4b_20260122_091115.json)
    Run 7: Invocation=0.957, Selection=0.727 (agent_test_results_qwen3_4b_20260123_075410.json)
    Run 8: Invocation=0.909, Selection=0.791 (agent_test_results_qwen3_4b_20260122_092025.json)
    Run 9: Invocation=1.000, Selection=0.929 (agent_test_results_qwen3_4b_20260118_173000.json)
    Run 10: Invocation=0.909, Selection=0.780 (agent_test_results_qwen3_4b_20260122_085327.json)
    Run 11: Invocation=0.957, Selection=0.868 (agent_test_results_qwen3_4b_20260122_084448.json)
    Run 12: Invocation=0.909, Selection=0.792 (agent_test_results_qwen3_4b_20260122_214145.json)
    Run 13: Invocation=1.000, Selection=0.906 (agent_test_results_qwen3_4b_20260118_150428.json)
    Run 14: Invocation=0.957, Selection=0.868 (agent_test_results_qwen3_4b_20260122_090140.json)
    Run 15: Invocation=1.000, Selection=0.897 (agent_test_results_qwen3_4b_20260118_183400.json)
    Run 16: Invocation=1.000, Selection=0.877 (agent_test_results_qwen3_4b_20260122_073656.json)
    Run 17: Invocation=1.000, Selection=0.929 (agent_test_results_qwen3_4b_20260122_094229.json)
    Run 18: Invocation=1.000, Selection=0.897 (agent_test_results_qwen3_4b_20260123_190032.json)
    Run 19: Invocation=1.000, Selection=0.945 (agent_test_results_qwen3_4b_20260122_081728.json)
    Run 20: Invocation=1.000, Selection=0.893 (agent_test_results_qwen3_4b_20260122_082723.json)
    Run 21: Invocation=1.000, Selection=0.926 (agent_test_results_qwen3_4b_20260122_083556.json)
    Run 22: Invocation=0.957, Selection=0.885 (agent_test_results_qwen3_4b_20260122_221748.json)

moonshotai_kimi-k2-thinking-maas:
  Batch Source: results
  Runs: 13, Unique Tests: 17
  Average Latency per LLM Call: 1.19s
  Tool Invocation (Binary, macro-averaged):
    Precision: 0.994 (153/154)
    Recall: 0.981 (153/156)
    F1: 0.987
  Tool Selection (macro-averaged):
    Precision: 0.873 (338/388)
    Recall: 0.843 (338/401)
    F1: 0.856
  Per-run F1 scores:
    Run 1: Invocation=1.000, Selection=0.787 (agent_test_results_moonshotai_kimi-k2-thinking-maas_20260208_152156.json)
    Run 2: Invocation=0.957, Selection=0.839 (agent_test_results_moonshotai_kimi-k2-thinking-maas_20260208_151939.json)
    Run 3: Invocation=1.000, Selection=0.892 (agent_test_results_moonshotai_kimi-k2-thinking-maas_20260208_153453.json)
    Run 4: Invocation=1.000, Selection=0.836 (agent_test_results_moonshotai_kimi-k2-thinking-maas_20260208_154141.json)
    Run 5: Invocation=1.000, Selection=0.933 (agent_test_results_moonshotai_kimi-k2-thinking-maas_20260208_154351.json)
    Run 6: Invocation=0.957, Selection=0.833 (agent_test_results_moonshotai_kimi-k2-thinking-maas_20260208_153920.json)
    Run 7: Invocation=1.000, Selection=0.828 (agent_test_results_moonshotai_kimi-k2-thinking-maas_20260208_154245.json)
    Run 8: Invocation=1.000, Selection=0.871 (agent_test_results_moonshotai_kimi-k2-thinking-maas_20260208_153804.json)
    Run 9: Invocation=1.000, Selection=0.871 (agent_test_results_moonshotai_kimi-k2-thinking-maas_20260208_153702.json)
    Run 10: Invocation=0.957, Selection=0.852 (agent_test_results_moonshotai_kimi-k2-thinking-maas_20260208_153559.json)
    Run 11: Invocation=0.960, Selection=0.820 (agent_test_results_moonshotai_kimi-k2-thinking-maas_20260208_153328.json)
    Run 12: Invocation=1.000, Selection=0.881 (agent_test_results_moonshotai_kimi-k2-thinking-maas_20260208_154037.json)
    Run 13: Invocation=1.000, Selection=0.889 (agent_test_results_moonshotai_kimi-k2-thinking-maas_20260208_152051.json)

nemotron-3-nano:
  Batch Source: results
  Runs: 9, Unique Tests: 17
  Average Latency per LLM Call: 15.22s
  Tool Invocation (Binary, macro-averaged):
    Precision: 1.000 (94/94)
    Recall: 0.870 (94/108)
    F1: 0.930
  Tool Selection (macro-averaged):
    Precision: 0.959 (195/204)
    Recall: 0.769 (195/253)
    F1: 0.852
  Per-run F1 scores:
    Run 1: Invocation=0.909, Selection=0.780 (agent_test_results_nemotron-3-nano_20260118_184912.json)
    Run 2: Invocation=0.957, Selection=0.851 (agent_test_results_nemotron-3-nano_20260123_081000.json)
    Run 3: Invocation=0.957, Selection=0.815 (agent_test_results_nemotron-3-nano_20260122_215516.json)
    Run 4: Invocation=0.957, Selection=0.889 (agent_test_results_nemotron-3-nano_20260118_174346.json)
    Run 5: Invocation=0.957, Selection=0.906 (agent_test_results_nemotron-3-nano_20260208_132851.json)
    Run 6: Invocation=0.957, Selection=0.885 (agent_test_results_nemotron-3-nano_20260118_155953.json)
    Run 7: Invocation=0.857, Selection=0.840 (agent_test_results_nemotron-3-nano_20260122_223310.json)
    Run 8: Invocation=0.909, Selection=0.863 (agent_test_results_nemotron-3-nano_20260123_191634.json)
    Run 9: Invocation=0.909, Selection=0.836 (agent_test_results_nemotron-3-nano_20260118_151722.json)

us.amazon.nova-micro-v1_0:
  Batch Source: results
  Runs: 5, Unique Tests: 17
  Average Latency per LLM Call: 0.82s
  Tool Invocation (Binary, macro-averaged):
    Precision: 0.969 (59/61)
    Recall: 0.983 (59/60)
    F1: 0.975
  Tool Selection (macro-averaged):
    Precision: 0.848 (124/146)
    Recall: 0.820 (124/151)
    F1: 0.832
  Per-run F1 scores:
    Run 1: Invocation=1.000, Selection=0.867 (agent_test_results_us.amazon.nova-micro-v1_0_20260118_162818.json)
    Run 2: Invocation=0.957, Selection=0.867 (agent_test_results_us.amazon.nova-micro-v1_0_20260118_191537.json)
    Run 3: Invocation=0.960, Selection=0.767 (agent_test_results_us.amazon.nova-micro-v1_0_20260118_215632.json)
    Run 4: Invocation=1.000, Selection=0.755 (agent_test_results_us.amazon.nova-micro-v1_0_20260118_165030.json)
    Run 5: Invocation=0.960, Selection=0.906 (agent_test_results_us.amazon.nova-micro-v1_0_20260122_181434.json)

qwen3_0.6b:
  Batch Source: results
  Runs: 9, Unique Tests: 17
  Average Latency per LLM Call: 2.44s
  Tool Invocation (Binary, macro-averaged):
    Precision: 1.000 (88/88)
    Recall: 0.815 (88/108)
    F1: 0.893
  Tool Selection (macro-averaged):
    Precision: 0.927 (187/203)
    Recall: 0.716 (187/261)
    F1: 0.804
  Per-run F1 scores:
    Run 1: Invocation=0.957, Selection=0.828 (agent_test_results_qwen3_0.6b_20260123_185558.json)
    Run 2: Invocation=0.957, Selection=0.885 (agent_test_results_qwen3_0.6b_20260118_150037.json)
    Run 3: Invocation=0.857, Selection=0.792 (agent_test_results_qwen3_0.6b_20260118_183009.json)
    Run 4: Invocation=0.857, Selection=0.731 (agent_test_results_qwen3_0.6b_20260118_145359.json)
    Run 5: Invocation=0.957, Selection=0.830 (agent_test_results_qwen3_0.6b_20260122_221319.json)
    Run 6: Invocation=0.857, Selection=0.667 (agent_test_results_qwen3_0.6b_20260118_172559.json)
    Run 7: Invocation=1.000, Selection=0.926 (agent_test_results_qwen3_0.6b_20260122_213718.json)
    Run 8: Invocation=0.857, Selection=0.816 (agent_test_results_qwen3_0.6b_20260118_154131.json)
    Run 9: Invocation=0.737, Selection=0.766 (agent_test_results_qwen3_0.6b_20260123_074956.json)

granite4_350m:
  Batch Source: results
  Runs: 9, Unique Tests: 17
  Average Latency per LLM Call: 0.57s
  Tool Invocation (Binary, macro-averaged):
    Precision: 0.885 (99/112)
    Recall: 0.917 (99/108)
    F1: 0.899
  Tool Selection (macro-averaged):
    Precision: 0.839 (175/209)
    Recall: 0.691 (175/253)
    F1: 0.754
  Per-run F1 scores:
    Run 1: Invocation=0.783, Selection=0.600 (agent_test_results_granite4_350m_20260118_183128.json)
    Run 2: Invocation=0.880, Selection=0.750 (agent_test_results_granite4_350m_20260118_150158.json)
    Run 3: Invocation=0.960, Selection=0.755 (agent_test_results_granite4_350m_20260118_145526.json)
    Run 4: Invocation=0.917, Selection=0.815 (agent_test_results_granite4_350m_20260123_075120.json)
    Run 5: Invocation=0.880, Selection=0.727 (agent_test_results_granite4_350m_20260118_154249.json)
    Run 6: Invocation=0.833, Selection=0.667 (agent_test_results_granite4_350m_20260122_213850.json)
    Run 7: Invocation=0.960, Selection=0.840 (agent_test_results_granite4_350m_20260118_172727.json)
    Run 8: Invocation=0.923, Selection=0.815 (agent_test_results_granite4_350m_20260123_185736.json)
    Run 9: Invocation=0.957, Selection=0.816 (agent_test_results_granite4_350m_20260122_221516.json)

functiongemma_latest:
  Batch Source: results
  Runs: 12, Unique Tests: 17
  Average Latency per LLM Call: 1.07s
  Tool Invocation (Binary, macro-averaged):
    Precision: 0.993 (132/133)
    Recall: 0.917 (132/144)
    F1: 0.953
  Tool Selection (macro-averaged):
    Precision: 0.990 (171/173)
    Recall: 0.562 (171/304)
    F1: 0.716
  Per-run F1 scores:
    Run 1: Invocation=0.917, Selection=0.732 (agent_test_results_functiongemma_latest_20260123_185501.json)
    Run 2: Invocation=0.957, Selection=0.750 (agent_test_results_functiongemma_latest_20260118_145947.json)
    Run 3: Invocation=0.957, Selection=0.750 (agent_test_results_functiongemma_latest_20260118_145307.json)
    Run 4: Invocation=0.957, Selection=0.750 (agent_test_results_functiongemma_latest_20260118_120352.json)
    Run 5: Invocation=0.957, Selection=0.684 (agent_test_results_functiongemma_latest_20260122_213617.json)
    Run 6: Invocation=0.957, Selection=0.684 (agent_test_results_functiongemma_latest_20260118_172510.json)
    Run 7: Invocation=0.957, Selection=0.684 (agent_test_results_functiongemma_latest_20260123_074904.json)
    Run 8: Invocation=0.957, Selection=0.718 (agent_test_results_functiongemma_latest_20260122_221214.json)
    Run 9: Invocation=0.957, Selection=0.732 (agent_test_results_functiongemma_latest_20260118_120530.json)
    Run 10: Invocation=0.957, Selection=0.739 (agent_test_results_functiongemma_latest_20260118_120759.json)
    Run 11: Invocation=0.957, Selection=0.718 (agent_test_results_functiongemma_latest_20260118_154042.json)
    Run 12: Invocation=0.957, Selection=0.649 (agent_test_results_functiongemma_latest_20260118_182918.json)

Overall Rankings (by Tool Selection F1):
-----------------------------------------
1. global.anthropic.claude-sonnet-4-5-20250929-v1_0 (F1: 0.964, Latency: 2.89s)
2. global.anthropic.claude-sonnet-4-20250514-v1_0 (F1: 0.957, Latency: 2.48s)
3. global.anthropic.claude-haiku-4-5-20251001-v1_0 (F1: 0.949, Latency: 1.67s)
4. zai-org_glm-4.7-maas (F1: 0.925, Latency: 1.39s)
5. global.amazon.nova-2-lite-v1_0 (F1: 0.920, Latency: 0.84s)
6. qwen3_8b (F1: 0.909, Latency: 9.22s)
7. qwen3_1.7b (F1: 0.906, Latency: 2.77s)
8. Qwen3-Coder-Next-UD-Q3_K_XL.gguf (F1: 0.901, Latency: 1.77s)
9. glm-4.7-flash (F1: 0.900, Latency: 3.46s)
10. gemini-2.0-flash (F1: 0.873, Latency: 1.29s)
11. gemini-2.5-pro (F1: 0.867, Latency: 4.51s)
12. qwen3_4b (F1: 0.859, Latency: 17.81s)
13. moonshotai_kimi-k2-thinking-maas (F1: 0.856, Latency: 1.19s)
14. nemotron-3-nano (F1: 0.852, Latency: 15.22s)
15. us.amazon.nova-micro-v1_0 (F1: 0.832, Latency: 0.82s)
16. qwen3_0.6b (F1: 0.804, Latency: 2.44s)
17. granite4_350m (F1: 0.754, Latency: 0.57s)
18. functiongemma_latest (F1: 0.716, Latency: 1.07s)

Summary:
--------
Analyzed 18 models across 179 total runs.
Best performing model: global.anthropic.claude-sonnet-4-5-20250929-v1_0 (Tool Selection F1: 0.964)
